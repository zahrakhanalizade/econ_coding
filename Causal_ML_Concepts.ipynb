{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMRpMYH6hqMhGyQjISEhDo6"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Causal Machine Learning â€” Concepts\n",
        "\n",
        "1. **Foundations**\n",
        "   - [Potential Outcomes Framework](#potential_outcomes)  \n",
        "     Define causal effects as comparisons of potential outcomes.  \n",
        "   - [Causal Graphs and DAGs](#causal_graphs)  \n",
        "     Visualize assumptions and dependencies using DAGs.  \n",
        "\n",
        "2. **Identification Assumptions**\n",
        "   - [Ignorability and Conditional Independence](#ignorability)  \n",
        "     When treatment assignment is as good as random after conditioning on covariates.  \n",
        "   - [Overlap and Positivity](#overlap)  \n",
        "     Every unit has a non-zero probability of receiving each treatment.  \n",
        "   - [SUTVA](#sutva)  \n",
        "     Stable Unit Treatment Value Assumption; no interference or hidden variations in treatment.  \n",
        "\n",
        "3. **Key Estimands**\n",
        "   - [ATE, ATT, CATE](#estimands)  \n",
        "     Clarify which treatment effect you are trying to estimate and why it matters.  \n",
        "\n",
        "4. **Families of Methods**\n",
        "   - [Propensity Score Based Methods](#propensity_methods)  \n",
        "     Matching, weighting, stratification. Why balancing matters.  \n",
        "   - [Outcome Regression](#outcome_regression)  \n",
        "     Modeling outcomes directly and its risks.  \n",
        "   - [Doubly Robust Approaches](#doubly_robust)  \n",
        "     Combine outcome and treatment models to reduce bias.  \n",
        "   - [Meta-Learners](#meta_learners)  \n",
        "     S, T, X, R learners. Strengths and weaknesses.  \n",
        "   - [Tree-Based and Ensemble Methods](#tree_methods)  \n",
        "     Causal trees and forests for heterogeneous effects.  \n",
        "   - [Panel and IV Methods](#panel_iv)  \n",
        "     Difference-in-differences, synthetic control, and IV with ML.  \n",
        "\n",
        "5. **Evaluation and Robustness**\n",
        "   - [Refutation Tests](#refutations)  \n",
        "     Placebo checks, data perturbation.  \n",
        "   - [Sensitivity Analysis](#sensitivity)  \n",
        "     Address hidden confounding and robustness to assumptions.  \n",
        "\n",
        "6. **Common Pitfalls and Caveats**\n",
        "   - [Data Overlap Problems](#overlap_issues)  \n",
        "     Why poor overlap makes estimation unstable.  \n",
        "   - [Extrapolation Risks](#extrapolation)  \n",
        "     ML models can extrapolate outside support.  \n",
        "   - [Finite Sample Bias](#finite_sample)  \n",
        "     Why small samples hurt flexible methods.  \n",
        "\n",
        "7. **Conceptual Wrap-Up**\n",
        "   - [When to Use Which Approach](#method_choice)  \n",
        "     Guidelines for choosing methods based on data and assumptions.  \n",
        "   - [Causal ML vs Predictive ML](#causal_vs_predictive)  \n",
        "     Why causal inference needs more than just predictive accuracy.  \n"
      ],
      "metadata": {
        "id": "dxYsY5VSP21T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 1. Foundations <a name=\"foundations\"></a>\n",
        "\n",
        "### Potential Outcomes Framework <a name=\"potential_outcomes\"></a>\n",
        "Causal effects are defined as comparisons between potential outcomes under treatment and control. The challenge is that only one outcome is observed per unit.\n",
        "\n",
        "### Causal Graphs and DAGs <a name=\"causal_graphs\"></a>\n",
        "Directed Acyclic Graphs (DAGs) are a visual tool for encoding causal assumptions. They help identify valid adjustment sets and clarify possible biases.\n"
      ],
      "metadata": {
        "id": "nlPtjjgXT5cQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 2. Identification Assumptions <a name=\"identification_assumptions\"></a>\n",
        "\n",
        "### Ignorability and Conditional Independence <a name=\"ignorability\"></a>\n",
        "Treatment assignment is independent of potential outcomes given observed covariates. This allows us to adjust for confounding.\n",
        "\n",
        "### Overlap and Positivity <a name=\"overlap\"></a>\n",
        "Every unit has a positive probability of receiving each treatment. Without overlap, causal effects are not identified.\n",
        "\n",
        "### SUTVA <a name=\"sutva\"></a>\n",
        "Stable Unit Treatment Value Assumption: no interference between units, and no hidden variations in treatment.\n"
      ],
      "metadata": {
        "id": "t2dTHQp1T7FE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 3. Key Estimands <a name=\"estimands\"></a>\n",
        "- **ATE (Average Treatment Effect):** Expected difference in outcomes between treated and control for the population.  \n",
        "- **ATT (Average Treatment Effect on the Treated):** Expected effect for those who actually received treatment.  \n",
        "- **CATE (Conditional Average Treatment Effect):** Expected effect conditional on covariates.  \n"
      ],
      "metadata": {
        "id": "ivg8xh65T7Hi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 4. Families of Methods <a name=\"families_of_methods\"></a>\n",
        "\n",
        "### Propensity Score Based Methods <a name=\"propensity_methods\"></a>\n",
        "Match or reweight observations to achieve balance between treated and control groups.\n",
        "\n",
        "### Outcome Regression <a name=\"outcome_regression\"></a>\n",
        "Model expected outcomes given covariates. Vulnerable to misspecification.\n",
        "\n",
        "### Doubly Robust Approaches <a name=\"doubly_robust\"></a>\n",
        "Combine outcome regression and propensity weighting. Consistent if either model is correct.\n",
        "\n",
        "### Meta-Learners <a name=\"meta_learners\"></a>\n",
        "Frameworks that use machine learning to estimate treatment effects:  \n",
        "- **S-Learner:** Single model with treatment as feature.  \n",
        "- **T-Learner:** Separate models for treated and control.  \n",
        "- **X-Learner:** Imputes treatment effects and then learns them.  \n",
        "- **R-Learner:** Uses orthogonalization for efficient estimation.  \n",
        "\n",
        "### Tree-Based and Ensemble Methods <a name=\"tree_methods\"></a>\n",
        "- **Causal Trees:** Partition data to estimate subgroup effects.  \n",
        "- **Honest Trees:** Split data into training and estimation sets to reduce bias.  \n",
        "- **Causal Forests:** Ensemble of causal trees for robust CATE estimates.  \n",
        "\n",
        "### Panel and IV Methods <a name=\"panel_iv\"></a>\n",
        "- **Difference-in-Differences:** Exploit before-and-after variation across groups.  \n",
        "- **Synthetic Control:** Construct weighted synthetic controls.  \n",
        "- **Instrumental Variables:** Use exogenous variation for identification.  \n"
      ],
      "metadata": {
        "id": "mMKPFGavT7J2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 5. Evaluation and Robustness <a name=\"evaluation\"></a>\n",
        "\n",
        "### Refutation Tests <a name=\"refutations\"></a>\n",
        "Placebo treatments or data perturbations to test robustness.\n",
        "\n",
        "### Sensitivity Analysis <a name=\"sensitivity\"></a>\n",
        "Quantify how sensitive results are to unobserved confounding.\n"
      ],
      "metadata": {
        "id": "XoAQUX91T7MZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 6. Common Pitfalls and Caveats <a name=\"pitfalls\"></a>\n",
        "\n",
        "### Data Overlap Problems <a name=\"overlap_issues\"></a>\n",
        "Lack of overlap leads to unstable or extrapolated estimates.\n",
        "\n",
        "### Extrapolation Risks <a name=\"extrapolation\"></a>\n",
        "ML models may extrapolate beyond observed support, producing unreliable effects.\n",
        "\n",
        "### Finite Sample Bias <a name=\"finite_sample\"></a>\n",
        "Flexible ML estimators can suffer from bias in small samples."
      ],
      "metadata": {
        "id": "svzIE0cnT7PQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 7. Conceptual Wrap-Up <a name=\"wrap_up\"></a>\n",
        "\n",
        "### When to Use Which Approach <a name=\"method_choice\"></a>\n",
        "Choose methods based on available data, plausibility of assumptions, and the estimand of interest.\n",
        "\n",
        "### Causal ML vs Predictive ML <a name=\"causal_vs_predictive\"></a>\n",
        "Causal ML requires identification assumptions and robustness checks, not just predictive accuracy."
      ],
      "metadata": {
        "id": "30MJmrZ1Uj2r"
      }
    }
  ]
}